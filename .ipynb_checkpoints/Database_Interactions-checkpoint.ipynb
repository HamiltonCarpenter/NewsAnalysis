{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper Functions Included\n"
     ]
    }
   ],
   "source": [
    "%run 'Misc_Helper_Funcs.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database_Interactions Included\n"
     ]
    }
   ],
   "source": [
    "print(\"Database_Interactions Included\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_scrape_table(mycursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DatabaseManager:\n",
    "\n",
    "    def __init__(self):\n",
    "        #def default_newsdatabase_connect():\n",
    "        self.mydb = mysql.connector.connect(\n",
    "          host=\"localhost\",\n",
    "          user=\"pythonuser\",\n",
    "          passwd=\"password\",\n",
    "          database=\"newsdatabase\"\n",
    "        ) \n",
    "\n",
    "        self.mycursor = self.mydb.cursor(buffered=True)\n",
    "#    return self.mycursor\n",
    "#self.mycursor = default_newsdatabase_connect()\n",
    "\n",
    "    def get_date_for_url_db(self, url):\n",
    "        sql = \"SELECT date FROM urls WHERE url= %s\"\n",
    "        val = (url,)\n",
    "\n",
    "        self.mycursor.execute(sql,val)\n",
    "        row = self.mycursor.fetchall()\n",
    "        assert(1 == len(row))\n",
    "        db_date = row[0][0]\n",
    "        obj_date = convert_m_d_y_to_date_object(db_date)\n",
    "        return obj_date\n",
    "\n",
    "    def get_outlet_for_url_db(self, url):\n",
    "        sql = \"SELECT outlet FROM urls WHERE url= %s\"\n",
    "        val = (url,)\n",
    "\n",
    "        self.mycursor.execute(sql,val)\n",
    "        row = self.mycursor.fetchall()\n",
    "        assert(1 == len(row))\n",
    "        outlet = row[0][0]\n",
    "        return outlet\n",
    "\n",
    "    def set_path_for_file_db(self, url, file_loc):\n",
    "        self.mycursor = self.mydb.cursor()\n",
    "        sql = \"UPDATE Rawtext SET File_Location = %s WHERE URL = %s\"\n",
    "        val = (file_loc, url)\n",
    "        self.mycursor.execute(sql,val)\n",
    "        self.mydb.commit()\n",
    "\n",
    "    def mark_url_as_scraped_db(self, url):\n",
    "        self.mycursor = self.mydb.cursor()\n",
    "        sql = \"UPDATE Rawtext SET Scraped = 1 WHERE URL = %s\"\n",
    "        val = (url,)\n",
    "        self.mycursor.execute(sql,val)\n",
    "        self.mydb.commit()\n",
    "\n",
    "    def get_unscraped_urls_from_db(self):\n",
    "        sql = \"SELECT * FROM Rawtext WHERE Scraped = 0\"\n",
    "\n",
    "        self.mycursor.execute(sql)\n",
    "        unscrapped = self.mycursor.fetchall()\n",
    "        return unscrapped\n",
    "\n",
    "\n",
    "    def check_present(self,url):\n",
    "        t = (url,)\n",
    "        #print(self.mycursor.execute('SELECT * FROM urls WHERE id=2'))\n",
    "        self.mycursor.execute('SELECT * FROM urls WHERE url=%s', t)\n",
    "        match = self.mycursor.fetchall()\n",
    "        return len(match) > 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def update_unscraped_article(self, url, file_location):\n",
    "        #self.mycursor = self.mydb.cursor()\n",
    "\n",
    "        sql = \"UPDATE Rawtext SET File_Location = %s WHERE URL = %s\"\n",
    "        val = (file_location, URL)\n",
    "\n",
    "        self.mycursor.execute(sql, val)\n",
    "\n",
    "        self.mydb.commit()\n",
    "\n",
    "        print(self.mycursor.rowcount, \"record(s) affected\") \n",
    "\n",
    "    def check_article_rawtext_present(self, url):\n",
    "        t = (url,)\n",
    "        #print(self.mycursor.execute('SELECT * FROM urls WHERE id=2'))\n",
    "        self.mycursor.execute('SELECT * FROM check WHERE url=%s', t)\n",
    "        match = self.mycursor.fetchall()\n",
    "        return len(match) > 0\n",
    "\n",
    "    def write_raw_text_to_db(self, url, rawtext):\n",
    "        if not check_article_rawtext_present(construct_full_url(url)):\n",
    "            #print(construct_full_url('/2019/08/19/us/politics/elizabeth-warren-native-american.html', 'NewYorkTimes'))\n",
    "            sql = \"INSERT INTO raw_articles (url, raw_article) VALUES (%s, %s)\"\n",
    "            val = (construct_full_url(link, outlet),date,outlet) #(\"https://www.nytimes.com\"+link, \"08/20/2019\",NewYorkTimes)\n",
    "            self.mycursor.execute(sql, val)\n",
    "\n",
    "            self.mydb.commit()\n",
    "\n",
    "            print(self.mycursor.rowcount, \"record inserted.\")\n",
    "\n",
    "    def update_scrape_table(self):\n",
    "        #connect to db\n",
    "\n",
    "        sql = \"SELECT * FROM urls WHERE url NOT IN (SELECT URL FROM Rawtext)\"\n",
    "\n",
    "        self.mycursor.execute(sql)\n",
    "        unscrapped = self.mycursor.fetchall()\n",
    "\n",
    "        insert_sql = \"INSERT INTO Rawtext (Scraped, URL, File_Location) VALUES (%s, %s, %s)\"\n",
    "        for x in unscrapped:\n",
    "\n",
    "            URL=x[0]\n",
    "            Scraped = 0\n",
    "            File_Location= None\n",
    "\n",
    "            insertval = (Scraped,URL,File_Location) #(\"https://www.nytimes.com\"+link, \"08/20/2019\",NewYorkTimes)\n",
    "            self.mycursor.execute(insert_sql, insertval)\n",
    "\n",
    "            self.mydb.commit()\n",
    "            print(URL+\" Transered\")\n",
    "\n",
    "    def update_parsed_table(self):\n",
    "        #connect to db\n",
    "\n",
    "        sql = \"SELECT URL FROM Rawtext WHERE URL NOT IN (SELECT URL FROM Parsedtext)\"\n",
    "\n",
    "        self.mycursor.execute(sql)\n",
    "        unscrapped = self.mycursor.fetchall()\n",
    "\n",
    "        insert_sql = \"INSERT INTO Parsedtext (Parsed, URL, File_Location) VALUES (%s, %s, %s)\"\n",
    "        for x in unscrapped:\n",
    "\n",
    "            URL=x[0]\n",
    "            Parsed = 0\n",
    "            File_Location= None\n",
    "\n",
    "            insertval = (Parsed,URL,File_Location) #(\"https://www.nytimes.com\"+link, \"08/20/2019\",NewYorkTimes)\n",
    "            self.mycursor.execute(insert_sql, insertval)\n",
    "\n",
    "            self.mydb.commit()\n",
    "            print(URL+\" Transered\")\n",
    "            \n",
    "    def get_uncleaned_urls_from_db(self):\n",
    "        sql = \"SELECT URL FROM Parsedtext WHERE Parsed = %s\"\n",
    "        val = (0,)\n",
    "\n",
    "        self.mycursor.execute(sql,val)\n",
    "        unscrapped = self.mycursor.fetchall()\n",
    "        return unscrapped\n",
    "        \n",
    "    def set_cleaned_file_location(self,url,file_location):\n",
    "        sql = \"UPDATE Parsedtext SET File_Location = %s, Parsed = %s WHERE URL = %s\"\n",
    "        val = (file_location, 1, url)\n",
    "\n",
    "        self.mycursor.execute(sql, val)\n",
    "\n",
    "        self.mydb.commit()\n",
    "\n",
    "        print(self.mycursor.rowcount, \"record(s) affected\") \n",
    "        \n",
    "            \n",
    "    def write_urls_to_db(self, url_list, outlet, category, date):\n",
    "        for link in url_list:\n",
    "            if not self.check_present(construct_full_url(link, outlet)):\n",
    "                #print(construct_full_url('/2019/08/19/us/politics/elizabeth-warren-native-american.html', 'NewYorkTimes'))\n",
    "                sql = \"INSERT INTO urls (url, date, outlet) VALUES (%s, %s, %s)\"\n",
    "                val = (construct_full_url(link, outlet),date,outlet) #(\"https://www.nytimes.com\"+link, \"08/20/2019\",NewYorkTimes)\n",
    "                self.mycursor.execute(sql, val)\n",
    "\n",
    "                self.mydb.commit()\n",
    "\n",
    "                print(self.mycursor.rowcount, \"record inserted.\")\n",
    "\n",
    "    def add_summary_to_db(self, url, outlet, same_stories, date):\n",
    "        sql = \"INSERT INTO StorySummaries (url, descriptors, same_stories, exact_duplicates, summary) VALUES (%s, %s, %s, %s, %s)\"\n",
    "        val = ('test_url',json.dumps({'meme':'memeval'}),json.dumps({'meme':'memeval'}),json.dumps({'meme':'memeval'}),'test summary') \n",
    "        #(\"https://www.nytimes.com\"+link, \"08/20/2019\",NewYorkTimes)\n",
    "        self.mycursor.execute(sql, val)\n",
    "\n",
    "        self.mydb.commit()\n",
    "\n",
    "        print(self.mycursor.rowcount, \"record inserted.\")\n",
    "                \n",
    "    \n",
    "                \n",
    "    #change to open new connection\n",
    "    def open_connection_db(self):\n",
    "        self.mydb = mysql.connector.connect(\n",
    "          host=\"localhost\",\n",
    "          user=\"pythonuser\",\n",
    "          passwd=\"password\",\n",
    "          database=\"newsdatabase\"\n",
    "        ) \n",
    "        self.mycursor = self.mydb.cursor(buffered=True) \n",
    "        return self.mycursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_data = json.dumps({'meme':'memeval'})\n",
    "\n",
    "#loaded_json = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "\n",
    "# a Python object (dict):\n",
    "#x = {\n",
    "#  \"name\": \"John\",\n",
    "#  \"age\": 30,\n",
    "#  \"city\": \"New York\"\n",
    "#}\n",
    "\n",
    "# convert into JSON:\n",
    "#y = json.dumps(x)\n",
    "\n",
    "# the result is a JSON string:\n",
    "#print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db = DatabaseManager()\n",
    "#db.add_summary_to_db('url', 'outlet', 'same_stories', 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE TABLE StorySummaries(url varchar(1000), descriptors json, same_stories json, exact_duplicates json, summary varchar(10000), id MEDIUMINT NOT NULL AUTO_INCREMENT, PRIMARY KEY (id) );"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
