{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper Functions Included\n"
     ]
    }
   ],
   "source": [
    "print(\"Helper Functions Included\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import re\n",
    "import browsercookie\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import datetime\n",
    "from time import sleep\n",
    "import requests \n",
    "import mysql.connector\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from urllib3.exceptions import MaxRetryError\n",
    "#import constant urllib3.exceptions.MaxRetryError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#class constants:\n",
    "NewYorkTimes = \"NewYorkTimes\"\n",
    "WashingtonPost = \"WashingtonPost\"\n",
    "politics = \"Politics\"\n",
    "raw = \"Raw\"\n",
    "clean = \"Clean\"\n",
    "standard_clean_directory = \"standard_clean_directory\"\n",
    "standard_raw_directory = \"standard_raw_directory\"\n",
    "\n",
    "outlets = {NewYorkTimes:{politics:\"https://www.nytimes.com/politics\"},WashingtonPost:{politics:\"https://www.washingtonpost.com/politics/\"}}\n",
    "    #make dict for sections and their unique identifiers \n",
    "identifiers = {NewYorkTimes:{politics:\"politics\"},WashingtonPost:{politics:\"politics\"}}\n",
    "\n",
    "\n",
    "    \n",
    "def get_date_string(): #duplicate\n",
    "    d = datetime.date.today()\n",
    "    return(str(d.month)+'/'+str(d.day)+'/'+str(d.year))\n",
    "\n",
    "\n",
    "#should move date to scrape database maybe have scrapedate and seendate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_full_url(scraped_url, outlet):\n",
    "    u = scraped_url\n",
    "    if outlet == \"NewYorkTimes\":\n",
    "        u = 'https://www.nytimes.com'+ u\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_m_d_y_to_date_object(mdy_string):\n",
    "    list_date = mdy_string.split('/')\n",
    "    year = list_date[2]\n",
    "    month = list_date[0]\n",
    "    day = list_date[1]\n",
    "    obj_date = datetime.date(int(year),int(month),int(day))\n",
    "    return obj_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
